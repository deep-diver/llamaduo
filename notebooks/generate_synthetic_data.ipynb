{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Generating instruction-answer pairs with Gemini\n",
        "\n",
        "References:\n",
        "\n",
        "* https://ai.google.dev/tutorials/python_quickstart\n",
        "* https://github.com/deep-diver/llmops-pipeline/issues/8#issue-2212315206"
      ],
      "metadata": {
        "id": "g9uN9ue0_47B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlvbFd996wHh"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "# GOOGLE_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "GOOGLE_API_KEY = userdata.get(\"GEMINI_ONE_API_KEY\")\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "E9LBHkZ67Cah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "    if \"generateContent\" in m.supported_generation_methods:\n",
        "        print(m.name)"
      ],
      "metadata": {
        "id": "1EPLdnSw61o2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_name = \"gemini-1.5-pro-latest\"\n",
        "model_name = \"gemini-1.0-ultra-latest\"\n",
        "\n",
        "model = genai.GenerativeModel(model_name)"
      ],
      "metadata": {
        "id": "SMsOxS467btm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "Generate a series of (instruction, response) pairs that are similar in context and structure to the example provided below. Each pair should consist of a concise instruction followed by an appropriate, detailed response. The instruction should pose a clear task or question, while the response should provide a comprehensive answer or solution that could be understood by someone with a basic understanding of the subject.\n",
        "\n",
        "Example pair:\n",
        "\n",
        "Instruction: This Java function below is not working as I expected, it's supposed to go through an array of numbers and if it finds a number in the array that is divisible by 2 with a remainder of 0, then it adds it to a new array and returns the new array at the end. Can you help debug the function and explain how why it's not working as expected?\\n\\npublic static List checkForEvens(int [] nums) {\\n ArrayList anwer = new ArrayList<Integer>();\\n for(int i = 0; i < nums.length; i++) {\\n if(nums[i] / 2 == 0) {\\n answer.add(nums[i]\\n } \\n }\\n}\n",
        "Response: Certainly! The function 'checkForEvens' iterates through an array and if a number in the array is divisible by 2, then it gets added to 'answer' which is later returned.\\n\\nThe reason the function may not be returning the expected result is because of the if statement, 'if (nums[i] /2 == 0)'. The statement is looking for numbers that get divided by 2 in the array and equal 0, which doesn't align with what you expect the function to do. \\n\\nInstead, you want to use the modulo operator to check for the remainder of a number that is being divided by 2. If a number is divided by 2 and returns a remainder of 0, then we can assume that it's an even number. So, the small change of 'if (nums[i] % 2 == 0)' should solve your issue. \\n\\nI've rewritten the function below with the correction.\\n\\npublic static List checkForEvens(int [] nums) {\\n ArrayList anwer = new ArrayList<Integer>();\\n for(int i = 0; i < nums.length; i++) {\\n if(nums[i] % 2 == 0) {\\n answer.add(nums[i]\\n } \\n }\\n}\n",
        "\n",
        "Your task is to generate more pairs that maintain this level of clarity and detail. The topic is Coding. Ensure that the responses are informative and accurate, suitable for an educational context.\n",
        "\n",
        "Store the generated pairs in JSON format, with each pair as an object within an array. Each object should have two key-value pairs: \"instruction\" and \"response\". For instance:\n",
        "\n",
        "[{\"instruction\": text, \"response\": text}, {\"instruction\": text, \"response\": text}, ...]\n",
        "\n",
        "Remember to maintain consistency in the format and ensure the generated pairs are diverse and cover a broad range of subjects. You must return the response\n",
        "in the asked format and you must not add any additional text in your response.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "E9kD7_ie9Fgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(prompt)"
      ],
      "metadata": {
        "id": "Tl1uCwhx8iS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_result = response.text\n",
        "text_result"
      ],
      "metadata": {
        "id": "nqi6KZ6piESu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown\n",
        "import textwrap\n",
        "\n",
        "def to_markdown(text):\n",
        "    text = text.replace('â€¢', '  *')\n",
        "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "to_markdown(text_result)"
      ],
      "metadata": {
        "id": "7WpXubHD9eIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def _find_json_snippet(raw_snippet):\n",
        "\t\"\"\"\n",
        "\t_find_json_snippet tries to find JSON snippets in a given raw_snippet string\n",
        "\t\"\"\"\n",
        "\tjson_parsed_string = None\n",
        "\n",
        "\tjson_start_index = raw_snippet.find('[')\n",
        "\tjson_end_index = raw_snippet.rfind(']')\n",
        "\n",
        "\tif json_start_index >= 0 and json_end_index >= 0:\n",
        "\t\tjson_snippet = raw_snippet[json_start_index:json_end_index+1]\n",
        "\t\ttry:\n",
        "\t\t\tjson_parsed_string = json.loads(json_snippet, strict=False)\n",
        "\t\texcept:\n",
        "\t\t\traise ValueError('......failed to parse string into JSON format')\n",
        "\telse:\n",
        "\t\traise ValueError('......No JSON code snippet found in string.')\n",
        "\n",
        "\treturn json_parsed_string"
      ],
      "metadata": {
        "id": "AMa-t4hJEx62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_find_json_snippet(text_result)"
      ],
      "metadata": {
        "id": "cf9B3Zig--ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generating similar responses with periodic hints from the original dataset"
      ],
      "metadata": {
        "id": "MBkd2xYYAFGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets -q -U"
      ],
      "metadata": {
        "id": "t7rxWFxn_KVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "existing_dataset = load_dataset(\"sayakpaul/no_robots_only_coding\", split=\"train_sft\")\n",
        "existing_dataset"
      ],
      "metadata": {
        "id": "dHIkri4S_L4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "existing_dataset[1][\"messages\"]"
      ],
      "metadata": {
        "id": "ofVfDOvr_tAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "num_periods = 5\n",
        "total_original_samples = len(existing_dataset)\n",
        "random_indices = np.random.randint(0, total_original_samples, size=(num_periods))\n",
        "random_indices"
      ],
      "metadata": {
        "id": "LLMCjuSQAKni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def craft_prompt(instruction, response):\n",
        "    prompt = \"\"\"\n",
        "Generate a series of (instruction, response) pairs that are similar in context and structure to the example provided below. Each pair should consist of a concise instruction followed by an appropriate, detailed response. The instruction should pose a clear task or question, while the response should provide a comprehensive answer or solution that could be understood by someone with a basic understanding of the subject.\n",
        "\n",
        "Example pair:\n",
        "\n",
        "Instruction: {instruction}\n",
        "Response: {response}\n",
        "\n",
        "Your task is to generate more pairs that maintain this level of clarity and detail. The topic is Coding. Ensure that the responses are informative and accurate, suitable for an educational context.\n",
        "\n",
        "Store the generated pairs in JSON format, with each pair as an object within an array. Each object should have two key-value pairs: \"instruction\" and \"response\". For instance:\n",
        "\n",
        "[{{\"instruction\": \"text\", \"response\": \"text\"}}, {{\"instruction\": \"text\", \"response\": \"text\"}}, ...]\n",
        "\n",
        "Remember to maintain consistency in the format and ensure the generated pairs are diverse and cover a broad range of subjects. You must return the response\n",
        "in the asked format and you must not add any additional text in your response.\n",
        "\"\"\"\n",
        "    return prompt.format(instruction=instruction, response=response)"
      ],
      "metadata": {
        "id": "vJhq_hsKiy7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = existing_dataset[1][\"messages\"]\n",
        "instruction = sample[0][\"content\"]\n",
        "response = sample[1][\"content\"]\n",
        "prompt_for_sample = craft_prompt(instruction, response)\n",
        "prompt_for_sample"
      ],
      "metadata": {
        "id": "dL72UlE6oFm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict\n",
        "\n",
        "def generate_with_gemini(prompt):\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n",
        "\n",
        "def format_response(responses: List[Dict[str, str]]):\n",
        "    final_instruction_answer_pair = []\n",
        "\n",
        "    for response in responses:\n",
        "        user_response_dict = {}\n",
        "        assistant_response_dict = {}\n",
        "        user_response_dict[\"content\"] = response[\"instruction\"]\n",
        "        user_response_dict[\"role\"] = \"user\"\n",
        "        assistant_response_dict[\"content\"] = response[\"response\"]\n",
        "        assistant_response_dict[\"role\"] = \"assistant\"\n",
        "\n",
        "        final_instruction_answer_pair.append([user_response_dict, assistant_response_dict])\n",
        "\n",
        "    return final_instruction_answer_pair"
      ],
      "metadata": {
        "id": "C6PemBS4Akfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_response_from_gemini = generate_with_gemini(prompt_for_sample)\n",
        "demo_response_from_gemini"
      ],
      "metadata": {
        "id": "n2KwIS3sBmHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_json = _find_json_snippet(demo_response_from_gemini)\n",
        "formatted_json"
      ],
      "metadata": {
        "id": "FAQj4V8ylVWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "demo_final_responses = format_response(formatted_json)\n",
        "demo_final_responses[0]"
      ],
      "metadata": {
        "id": "rrpGs8D4lUCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concurrent requests"
      ],
      "metadata": {
        "id": "lQ5rcM5Aw9dg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aiohttp asyncio -U -q"
      ],
      "metadata": {
        "id": "LZrOM-4kxBYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import aiohttp\n",
        "\n",
        "\n",
        "model_name = \"gemini-1.0-ultra-latest\"\n",
        "\n",
        "async def generate_text(prompt):\n",
        "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/{model_name}:generateContent?key={GOOGLE_API_KEY}\"\n",
        "    data = {\"contents\":[{\"parts\":[{\"text\": prompt}]}]}\n",
        "\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        async with session.post(url, json=data) as response:\n",
        "            if response.status == 200:\n",
        "                result = await response.json()\n",
        "                return result\n",
        "            else:\n",
        "                print(f\"Error: {response.status}\")\n",
        "                return None"
      ],
      "metadata": {
        "id": "srs3n5mdxAqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tasks = [generate_text(prompt_for_sample)]\n",
        "results = await asyncio.gather(*tasks)\n",
        "results[0]"
      ],
      "metadata": {
        "id": "aHa6p7jPxjMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results[0][\"candidates\"][0][\"content\"][\"parts\"]"
      ],
      "metadata": {
        "id": "Gq4zu-P85Cf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_find_json_snippet(results[0][\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "35MYDt4e5R7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare dataset"
      ],
      "metadata": {
        "id": "DqudZZz5rHqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is better run from a script rather than a notebook. The following script can also be refactored later. I also propose to first collect all the Gemini responses and serialize them in a simple JSON file.\n",
        "\n",
        "Once that's done it will be pretty easy to use another script to format the results and have them compatible with `datasets`."
      ],
      "metadata": {
        "id": "KYTrrdx-yT94"
      }
    }
  ]
}